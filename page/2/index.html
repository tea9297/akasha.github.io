<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/project/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/project/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/project/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/project/images/logo.svg" color="#222">

<link rel="stylesheet" href="/project/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+TC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"akasha.github.io","root":"/project/","images":"/project/images","scheme":"Muse","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"},"path":"/project/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/project/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="akasha使用手冊">
<meta property="og:url" content="https://akasha.github.io/project/page/2/index.html">
<meta property="og:site_name" content="akasha使用手冊">
<meta property="og:locale" content="zh_TW">
<meta property="article:author" content="Chih Chuan Chang&lt;ccchang@iii.org.tw&gt;">
<meta property="article:tag" content="akasha, manual, llm, rag">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://akasha.github.io/project/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-TW","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>akasha使用手冊</title>
  








  <noscript>
    <link rel="stylesheet" href="/project/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/project/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">akasha使用手冊</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">akasha manual</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜尋" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/project/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a></li><li class="menu-item menu-item-tags"><a href="/project/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤</a></li><li class="menu-item menu-item-categories"><a href="/project/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分類</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜尋
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜尋..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chih Chuan Chang<ccchang@iii.org.tw></p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/project/archives/">
          <span class="site-state-item-count">33</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/project/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分類</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-TW" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://akasha.github.io/project/2024/06/24/%E4%BB%A3%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/project/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha使用手冊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | akasha使用手冊">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/project/2024/06/24/%E4%BB%A3%E7%90%86/" class="post-title-link" itemprop="url">代理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2024-06-24 08:21:14" itemprop="dateCreated datePublished" datetime="2024-06-24T08:21:14+08:00">2024-06-24</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2><p>使用代理(agent)可以賦予語言模型其他能力，以便完成你下的指令，例如提供文件编辑、google搜尋的工具，便可以使語言模型提供更準確地回答，也可以請他幫忙儲存或刪除文件。</p>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><p>在範例1中，創建了一個可以讓使用者輸入文字的工具，也提供給代理一個將文字儲存成json檔案的工具。創建代理後，我們指示它詢問用戶問題，並將結果儲存到default.json中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">input_func</span>(<span class="params">question: <span class="built_in">str</span></span>):</span><br><span class="line">    response = <span class="built_in">input</span>(question)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(&#123;<span class="string">&quot;question&quot;</span>: question, <span class="string">&quot;answer&quot;</span>: response&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input_tool = akasha.create_tool(</span><br><span class="line">    <span class="string">&quot;user_question_tool&quot;</span>,</span><br><span class="line">    <span class="string">&quot;This is the tool to ask user question, the only one param question is the question string that has not been answered and we want to ask user.&quot;</span>,</span><br><span class="line">    func=input_func)</span><br><span class="line"></span><br><span class="line">ao = akasha.test_agent(verbose=<span class="literal">True</span>,</span><br><span class="line">                    tools=[</span><br><span class="line">                        input_tool,</span><br><span class="line">                        akasha.get_saveJSON_tool(),</span><br><span class="line">                    ],</span><br><span class="line">                    model=<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    ao(<span class="string">&quot;逐個詢問使用者以下問題，若所有問題都回答了，則將所有問題和回答儲存成default.json並結束。問題為:1.房間燈關了嗎? \n2. 有沒有人在家?  \n3.有哪些電器開啟?\n&quot;</span></span><br><span class="line">        ))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">I have successfully saved all the questions and answers into the &quot;default.json&quot; file. The conversation is now complete.</span><br><span class="line"></span><br><span class="line">### default.json ###</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;question&quot;: &quot;房間燈關了嗎?&quot;,</span><br><span class="line">        &quot;answer&quot;: &quot;no&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;question&quot;: &quot;有沒有人在家?&quot;,</span><br><span class="line">        &quot;answer&quot;: &quot;no&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;question&quot;: &quot;有哪些電器開啟?&quot;,</span><br><span class="line">        &quot;answer&quot;: &quot;phone, shower&quot;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>

<p>在範例二中，我們添加了wikipedia工具，讓語言模型能透過Wikipedia API查詢必要的資訊來幫助回答。由於wiki的回答中可能包含不必要的資訊，我們可以使用retri_observation來擷取與問題有關的回答。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ao = akasha.test_agent(</span><br><span class="line">        verbose=<span class="literal">True</span>,</span><br><span class="line">        tools=[input_tool,</span><br><span class="line">               akasha.get_saveJSON_tool(),</span><br><span class="line">               akasha.get_wiki_tool()],</span><br><span class="line">        retri_observation=<span class="literal">True</span>,</span><br><span class="line">        model=<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(ao(<span class="string">&quot;請用中文回答李遠哲跟黃仁勳誰比較老?將查到的資訊和答案儲存成json檔案，檔名為AGE.json&quot;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">根據查到的資訊，李遠哲（Yuan T. Lee）比黃仁勳（Jensen Huang）更老。李遠哲於1936年11月19日出生，而黃仁勳的出生日期是1963年2月17日。我已將這些資訊儲存成名為&quot;AGE.json&quot;的</span><br><span class="line">JSON檔案。</span><br><span class="line"></span><br><span class="line">### AGE.json ###</span><br><span class="line">&#123;</span><br><span class="line">    &quot;李遠哲&quot;: &quot;1936-11-19&quot;,</span><br><span class="line">    &quot;黃仁勳&quot;: &quot;1963-02-17&quot;,</span><br><span class="line">    &quot;答案&quot;: &quot;李遠哲比黃仁勳更老&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="stream"><a href="#stream" class="headerlink" title="stream"></a>stream</h3><p>若你想及時得到每輪agent的回應，可以使用stream function，此函式將每輪agent的回應回傳為generator</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ao = akasha.test_agent(</span><br><span class="line">        verbose=True,</span><br><span class="line">        tools=[input_tool,</span><br><span class="line">               akasha.get_saveJSON_tool(),</span><br><span class="line">               akasha.get_wiki_tool()],</span><br><span class="line">        retri_observation=True,</span><br><span class="line">        model=&quot;openai:gpt-3.5-turbo&quot;)</span><br><span class="line">st = ao.stream(&quot;請用中文回答李遠哲跟黃仁勳誰比較老?將查到的資訊和答案儲存成json檔案，檔名為AGE.json&quot;)</span><br><span class="line">for s in st:</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure>

</br>
</br>
</br>
</br>

<h3 id="test-agent-中的所有參數"><a href="#test-agent-中的所有參數" class="headerlink" title="test_agent 中的所有參數:"></a>test_agent 中的所有參數:</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Args:</span><br><span class="line">   model (str, optional): 使用的大語言模型. Defaults to &quot;gpt-3.5-turbo&quot;.\n</span><br><span class="line">   verbose (bool, optional): 是否顯示log文字. Defaults to False.\n</span><br><span class="line">   language (str, optional): 用來計算文字長度(max_doc_len)的語言. Defaults to &quot;zh&quot;</span><br><span class="line">   temperature (float, optional): 大語言模型的temperature(0.0 ~ 1.0) . Defaults to 0.0.\n</span><br><span class="line">   keep_logs (bool, optional)**: 是否紀錄執行的log. Defaults to False.\n</span><br><span class="line">   max_round (int, optional)**: agent最多執行次數，超過即跳出，避免無線迴圈. Defaults to 20.\n</span><br><span class="line">   max_doc_len (int, optional): agent保留的之前做過的思考與動作的文字最大長度. Defaults to 1800.\n</span><br><span class="line">   max_past_observation (int, optional)**: agent保留的之前做過的思考與動作的最多次數. Defaults to 10.\n</span><br><span class="line">   retri_observation (bool, optional)**: 若設為True, agent會利用大語言模型去擷取tool回傳內容，避免多餘文字輸入. Defaults to False.\n</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://akasha.github.io/project/2024/04/29/auto_create_questionset/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/project/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha使用手冊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | akasha使用手冊">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/project/2024/04/29/auto_create_questionset/" class="post-title-link" itemprop="url">auto_create_questionset</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2024-04-29 07:51:58" itemprop="dateCreated datePublished" datetime="2024-04-29T07:51:58+08:00">2024-04-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="自動產生問題"><a href="#自動產生問題" class="headerlink" title="自動產生問題"></a>自動產生問題</h2><p>如果您不想自己創建問題集來評估當前參數的性能，您可以使用 <em><strong>eval.auto_create_questionset</strong></em> 功能自動生成一個包含參考答案的問題集。隨後，您可以使用 <em><strong>eval.auto_evaluation</strong></em> 獲取評估指標，如 Bert_score、Rouge 和 LLM_score（對於問答問題集），以及單選問題集的正確率。這些分數範圍從 0 到 1，較高的值表示生成的回答與參考答案更接近。</p>
<p>如範例，以下創建了一個名為 ‘mic_essay.txt’ 的問題集文本文件，其中包含十個問題和參考答案。每個問題都是從 ‘doc&#x2F;mic&#x2F;‘ 目錄中給定文檔的內容段落中隨機生成的。然後，您可以使用該問題集文本文件來評估要測試的參數的性能。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import akasha.eval as eval</span><br><span class="line"></span><br><span class="line">eva = eval.Model_Eval(question_style=&quot;essay&quot;, search_type=&#x27;merge&#x27;,\</span><br><span class="line">      model=&quot;openai:gpt-3.5-turbo&quot;, embeddings=&quot;openai:text-embedding-ada-002&quot;,record_exp=&quot;exp_mic_auto_questionset&quot;)</span><br><span class="line"></span><br><span class="line">eva.auto_create_questionset(doc_path=&quot;doc/mic/&quot;, question_num=10, output_file_path=&quot;questionset/mic_essay.txt&quot;)</span><br><span class="line"></span><br><span class="line">bert_score, rouge, llm_score, tol_tokens = eva.auto_evaluation(questionset_file=&quot;questionset/mic_essay.txt&quot;, doc_path=&quot;doc/mic/&quot;, question_style = &quot;essay&quot;, record_exp=&quot;exp_mic_auto_evaluation&quot;,topK=3,search_type=&quot;svm&quot;)</span><br><span class="line">print(&quot;bert_score: &quot;, bert_score, &quot;\nrouge: &quot;, rouge, &quot;\nllm_score: &quot;, llm_score)</span><br></pre></td></tr></table></figure>

<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bert_score: 0.782</span><br><span class="line">rouge: 0.81</span><br><span class="line">llm_score: 0.393</span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="使用question-type測試不同方面的能力"><a href="#使用question-type測試不同方面的能力" class="headerlink" title="使用question_type測試不同方面的能力"></a>使用question_type測試不同方面的能力</h2><p>question_type 参数提供了四種問題類型：<em><strong>fact</strong></em>、<em><strong>summary</strong></em>、<em><strong>irrelevant</strong></em>、<em><strong>compared</strong></em>，預設是 fact。 </p>
<ol>
<li>fact測試回答一般事實的能力</li>
<li>summary測試模型做摘要的能力</li>
<li>irrelevant測試模型能否分辨文件中不存在答案的問題</li>
<li>compared測試模型比較不同事物的能力</li>
</ol>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import akasha.eval as eval</span><br><span class="line"></span><br><span class="line">eva = eval.Model_Eval(search_type=&#x27;merge&#x27;, question_type = &quot;irrelevant&quot;, model=&quot;openai:gpt-3.5-turbo&quot;, record_exp=&quot;exp_mic_auto_questionset&quot;)</span><br><span class="line"></span><br><span class="line">eva.auto_create_questionset(doc_path=&quot;doc/mic/&quot;, question_num=10, output_file_path=&quot;questionset/mic_irre.txt&quot;)</span><br><span class="line"></span><br><span class="line">bert_score, rouge, llm_score, tol_tokens = eva.auto_evaluation(questionset_file=&quot;questionset/mic_irre.txt&quot;, doc_path=&quot;doc/mic/&quot;, question_style = &quot;essay&quot;, record_exp=&quot;exp_mic_auto_evaluation&quot;,search_type=&quot;svm&quot;)</span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="指定問題集主題"><a href="#指定問題集主題" class="headerlink" title="指定問題集主題"></a>指定問題集主題</h2><p>如果你想生成特定主題的問題，你可以使用 <em><strong>create_topic_questionset</strong></em> 函數，它會使用輸入的主題在文檔中找到相關的文件段落並生成問題集。</p>
<h3 id="範例-1"><a href="#範例-1" class="headerlink" title="範例"></a>範例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import akasha.eval as eval</span><br><span class="line"></span><br><span class="line">eva = eval.Model_Eval(search_type=&#x27;merge&#x27;,question_type = &quot;irrelevant&quot;, model=&quot;openai:gpt-3.5-turbo&quot;, record_exp=&quot;exp_mic_auto_questionset&quot;)</span><br><span class="line"></span><br><span class="line">eva.create_topic_questionset(doc_path=&quot;doc/mic/&quot;, topic= &quot;工業4.0&quot;, question_num=3, output_file_path=&quot;questionset/mic_topic_irre.txt&quot;)</span><br><span class="line"></span><br><span class="line">bert_score, rouge, llm_score, tol_tokens = eva.auto_evaluation(questionset_file=&quot;questionset/mic_topic_irre.txt&quot;, doc_path=&quot;doc/mic/&quot;, question_style = &quot;essay&quot;, record_exp=&quot;exp_mic_auto_evaluation&quot;,search_type=&quot;svm&quot;)</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://akasha.github.io/project/2024/04/29/optimum_combination/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/project/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha使用手冊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | akasha使用手冊">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/project/2024/04/29/optimum_combination/" class="post-title-link" itemprop="url">optimum_combination</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2024-04-29 07:50:16" itemprop="dateCreated datePublished" datetime="2024-04-29T07:50:16+08:00">2024-04-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Find-Optimum-Combination"><a href="#Find-Optimum-Combination" class="headerlink" title="Find Optimum Combination"></a>Find Optimum Combination</h2><p>若要測試所有可用的組合並找到最佳參數，您可以使用 optimum_combination 函數。您可以提供不同的嵌入模型、文件段落大小、語言模型、文件搜索方法以及最相關文檔的數量（topK），該函數將測試所有組合以找到根據給定的問題集和文檔的最佳組合。請注意，最佳得分組合是最高正確率組合，而最佳性價比組合是需要最少token以獲得正確答案的組合。</p>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import akasha.eval as eval</span><br><span class="line">import os</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">load_dotenv() </span><br><span class="line"></span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your openAI key&quot;</span><br><span class="line">os.environ[&quot;HF_TOKEN&quot;] = &quot;your huggingface key&quot;</span><br><span class="line">dir_path = &quot;doc/pvc/&quot;</span><br><span class="line">exp_name = &quot;exp_akasha_optimum_combination&quot;</span><br><span class="line">embeddings_list = [&quot;hf:shibing624/text2vec-base-chinese&quot;, &quot;openai:text-embedding-ada-002&quot;]</span><br><span class="line">model_list = [&quot;openai:gpt-3.5-turbo&quot;,&quot;hf:FlagAlpha/Llama2-Chinese-13b-Chat-4bit&quot;,&quot;hf:meta-llama/Llama-2-7b-chat-hf&quot;,\</span><br><span class="line">            &quot;llama-gpu:model/llama-2-7b-chat.Q5_K_S.gguf&quot;, &quot;llama-gpu:model/llama-2-13b-chat.Q5_K_S.gguf&quot;]</span><br><span class="line"></span><br><span class="line">eva = eval.Model_Eval(question_style=&quot;single_choice&quot;)</span><br><span class="line">eva.optimum_combination(&quot;question_pvc.txt&quot;, dir_path,  embeddings_list = embeddings_list, model_list = model_list,</span><br><span class="line">            chunk_size_list=[200, 400, 600], search_type_list=[&quot;merge&quot;,&quot;tfidf&quot;,],record_exp=exp_name)</span><br></pre></td></tr></table></figure>


<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Best correct rate:  1.000</span><br><span class="line">Best score combination:  </span><br><span class="line"></span><br><span class="line">embeddings: openai:text-embedding-ada-002, chunk size: 400, model: openai:gpt-3.5-turbo, search type: merge</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">embeddings: openai:text-embedding-ada-002, chunk size: 400, model: openai:gpt-3.5-turbo, search type: tfidf</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">Best cost-effective:</span><br><span class="line"></span><br><span class="line">embeddings: hf:shibing624/text2vec-base-chinese, chunk size: 400, model: openai:gpt-3.5-turbo, search type: tfidf</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://akasha.github.io/project/2024/04/29/ask_agent/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/project/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha使用手冊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | akasha使用手冊">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/project/2024/04/29/ask_agent/" class="post-title-link" itemprop="url">ask_agent</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2024-04-29 07:45:08" itemprop="dateCreated datePublished" datetime="2024-04-29T07:45:08+08:00">2024-04-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="ask-agent"><a href="#ask-agent" class="headerlink" title="ask_agent"></a>ask_agent</h2><p>如果你想詢問較複雜的問題，使用ask_agent，語言模型會將你的問題拆解來提供較好的回答。</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ak = akasha.Doc_QA(</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    chunk_size=<span class="number">500</span>,</span><br><span class="line">    model=<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>,</span><br><span class="line">)</span><br><span class="line">res = ak.ask_agent(</span><br><span class="line">    <span class="string">&quot;./docs/mic/&quot;</span>,     </span><br><span class="line">    <span class="string">&quot;LPWAN和5G的區別是什麼?&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">LPWAN和5G的主要區別在於他們的頻寬、延遲、成本和應用場景。</span><br><span class="line"></span><br><span class="line">LPWAN的頻寬相對較低（0.3 KBps – 50KBps），延遲較高（秒 - 分），且成本較低。它的主要優點是低耗能、支援長距離傳輸，並且可以連接大量的設備。然而，由於其頻寬和延遲的限制，LPWAN在製造業中的</span><br><span class="line">應用主要適用於非即時、非關鍵性的應用，例如環境污染偵測、照明、人員移動等，且須長時間穩定使用的應用情境。</span><br><span class="line"></span><br><span class="line">相較之下，5G提供的頻寬範圍在1-10 Gbps，而延遲則在1-10 ms之間，成本較高。這使得5G非常適合需要高時序精密度的應用，例如異質設備協作、遠端操控、混合現實（MR）巡檢維修等。此外，5G網路在大型</span><br><span class="line">廠區中，相較於Wi-Fi，無移交控制（Handover）中斷問題，因此更適合如低延遲、快速移動型的自主移動機器人（AMR）或無人機（Drone）廣域應用。然而，5G私網的建置成本相對昂貴，可能會影響企業的導 </span><br><span class="line">入意願。</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://akasha.github.io/project/2024/04/29/%E5%AE%89%E8%A3%9D&%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/project/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha使用手冊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | akasha使用手冊">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/project/2024/04/29/%E5%AE%89%E8%A3%9D&%E4%BD%BF%E7%94%A8/" class="post-title-link" itemprop="url">安裝&使用</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2024-04-29 07:31:34" itemprop="dateCreated datePublished" datetime="2024-04-29T07:31:34+08:00">2024-04-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="安裝WSL"><a href="#安裝WSL" class="headerlink" title="安裝WSL"></a>安裝WSL</h2><p>如果你是linux 使用者可以跳過這個步驟，windows使用者建議安裝Windows子系統(WSL)，直接在Windows 執行Linux，請先確認windows版本是 Windows 10 版本 2004(組建 19041 和更新版本)或 Windows 11以上的版本才能安裝WSL。<br>先搜尋PowerShell，以系統管理員開啟 PowerShell執行WSL並安裝linux ubuntu，安裝完畢後要重新開機。</p>
<h3 id="install-wsl"><a href="#install-wsl" class="headerlink" title="install wsl"></a>install wsl</h3><p>安裝WSL並且安裝linux ubuntu。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ wsl --install</span><br></pre></td></tr></table></figure>
<p>安裝完畢，重新開機</p>
<h3 id="更新ubuntu"><a href="#更新ubuntu" class="headerlink" title="更新ubuntu"></a>更新ubuntu</h3><p>重新開機後，開啟wsl，更新ubuntu到最新版本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update -y &amp;&amp; sudo apt upgrade -y</span><br></pre></td></tr></table></figure>

<h3 id="更新系統套件到最新版本"><a href="#更新系統套件到最新版本" class="headerlink" title="更新系統套件到最新版本"></a>更新系統套件到最新版本</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$sudo apt update &amp;&amp; upgrade</span><br></pre></td></tr></table></figure>
<h3 id="安裝curl-套件"><a href="#安裝curl-套件" class="headerlink" title="安裝curl 套件"></a>安裝curl 套件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$sudo apt install curl</span><br></pre></td></tr></table></figure>
<h3 id="安裝anaconda"><a href="#安裝anaconda" class="headerlink" title="安裝anaconda"></a>安裝anaconda</h3><p>###先建立一個資料夾</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$mkdir temp</span><br></pre></td></tr></table></figure>

<p>###進入資料夾</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$cd temp</span><br></pre></td></tr></table></figure>
<p>###下載anaconda.sh </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$curl https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh --output anaconda.sh</span><br></pre></td></tr></table></figure>
<p>###安裝anaconda</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$bash anaconda.sh</span><br></pre></td></tr></table></figure>

<h3 id="新增conda-指令"><a href="#新增conda-指令" class="headerlink" title="新增conda 指令"></a>新增conda 指令</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$source ~/.bashrc</span><br></pre></td></tr></table></figure>

<h3 id="確認conda-有安裝成功"><a href="#確認conda-有安裝成功" class="headerlink" title="確認conda 有安裝成功"></a>確認conda 有安裝成功</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$conda info</span><br></pre></td></tr></table></figure>


<h2 id="使用anaconda和pip安裝akasha套件"><a href="#使用anaconda和pip安裝akasha套件" class="headerlink" title="使用anaconda和pip安裝akasha套件"></a>使用anaconda和pip安裝akasha套件</h2><p>Linux使用者安裝完畢anaconda，進行安裝akasha套件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">###create environment</span><br><span class="line">$ conda create --name py3-8 python=3.8</span><br><span class="line">$ activate py3-8</span><br><span class="line"></span><br><span class="line">###install akasha</span><br><span class="line">$ pip install akasha-terminal</span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="在Python中使用"><a href="#在Python中使用" class="headerlink" title="在Python中使用"></a>在Python中使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#PYTHON3.8</span></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line">ak = akasha.Doc_QA()</span><br><span class="line">response = ak.get_response(dir_path, prompt, model=<span class="string">&quot;hf:meta-llama/Llama-2-7b-chat-hf&quot;</span>)</span><br></pre></td></tr></table></figure>
</br>
</br>

<h2 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h2><p>在terminal上輸入，便會開起streamlit使用介面</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ akasha ui</span><br></pre></td></tr></table></figure>
</br>

<p>在瀏覽器中開啟 <a target="_blank" rel="noopener" href="http://localhost:8501/">http://localhost:8501/</a> <img src="https://hackmd.io/_uploads/Hkh8vijKT.png" alt="ui_5"> </p>
</br>
</br>

<h2 id="CLI"><a href="#CLI" class="headerlink" title="CLI"></a>CLI</h2><p>透過command line interface使用akasha，你可以用’keep-responsing’來建立一個文檔問答模型，並可以提出不同的問題，根據給定目錄中的文檔獲取語言模型的回答。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">akasha keep-responsing -d ../doc/plc/  -c 400 -k 1</span></span><br><span class="line">Please input your question(type &quot;exit()&quot; to quit) : 應回收廢塑膠容器材質種類不包含哪種?  聚丙烯（PP） 聚苯乙烯（PS） 聚氯乙烯（PVC）  低密度聚乙烯（LDPE）</span><br><span class="line">Response:  應回收廢塑膠容器材質種類不包含低密度聚乙烯（LDPE）。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Please input your question(type &quot;exit()&quot; to quit) : 所謂市盈率，是指每股市價除以每股盈餘，也就是股票的?   本益比  帳面值比  派息   資金</span><br><span class="line">英國和德國等多個市場。然而，義大利、加拿大和澳洲並不在這些可交易的國家之列。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Please input your question(type &quot;exit()&quot; to quit) : exit()</span><br></pre></td></tr></table></figure>

</br>
</br>

<p>現在可使用的指令: <em><strong>get-response</strong></em>, <em><strong>keep-responsing</strong></em>, <em><strong>chain-of-thought</strong></em>, <em><strong>auto-create-questionset</strong></em> and <em><strong>auto-evaluation</strong></em>.</p>
</br>


<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">akasha keep-responsing --<span class="built_in">help</span></span></span><br><span class="line">Usage: akasha keep-responsing [OPTIONS]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -d, --doc_path TEXT         document directory path, parse all .txt, .pdf,</span><br><span class="line">                              .docx files in the directory  [required]</span><br><span class="line">  -e, --embeddings TEXT       embeddings for storing the documents</span><br><span class="line">  -c, --chunk_size INTEGER    chunk size for storing the documents</span><br><span class="line">  -m, --model TEXT            llm model for generating the response</span><br><span class="line">  -ur --use_rerank BOOL       use rerank to sort the documents</span><br><span class="line">  -t, --threshold FLOAT       threshold score for selecting the relevant</span><br><span class="line">                              documents</span><br><span class="line">  -l, --language TEXT         language for the documents, default is &#x27;ch&#x27; for</span><br><span class="line">                              chinese</span><br><span class="line">  -s, --search_type TEXT      search type for the documents, include merge,</span><br><span class="line">                              svm, mmr, tfidf</span><br><span class="line">  -sys, --system_prompt TEXT  system prompt for the llm model</span><br><span class="line">  -md, --max_doc_len INTEGER    max document length for the llm model input</span><br><span class="line">  --help                      Show this message and exit.</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://akasha.github.io/project/2024/04/10/ask_whole_file/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/project/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha使用手冊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | akasha使用手冊">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/project/2024/04/10/ask_whole_file/" class="post-title-link" itemprop="url">ask_whole_file</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2024-04-10 08:26:16" itemprop="dateCreated datePublished" datetime="2024-04-10T08:26:16+08:00">2024-04-10</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="ask-whole-file"><a href="#ask-whole-file" class="headerlink" title="ask_whole_file"></a>ask_whole_file</h2><p>如果你想詢問單個檔案的內容，且該文件檔不長，在語言模型的窗口大小內，你可以使用ask_whole_file將整個文件的內容給語言模型做為參考。</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA(</span><br><span class="line">    search_type=&quot;merge&quot;,</span><br><span class="line">    verbose=True,</span><br><span class="line">    max_doc_len=15000,</span><br><span class="line">    model=&quot;openai:gpt-4-32k&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">response = ak.ask_whole_file(system_prompt=&quot;用列舉的方式描述&quot;,</span><br><span class="line">    file_path=&quot;docs/mic/20230726_工業4_0發展重點與案例分析，以西門子、鴻海為例.pdf&quot;,</span><br><span class="line">    prompt=&quot;工業4.0有什麼可以參考的標準或是架構嗎?&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">工業4.0的參考標準或架構主要有以下幾種：</span><br><span class="line"></span><br><span class="line">1. 「工業 4.0成熟度指數」：由德國國家工程院（Acatech）提出，將發展階段劃分為電腦化、可連結、可視化、可分析、可預測、自適應共六個成熟度，前項為後項發展基礎。</span><br><span class="line"></span><br><span class="line">2. 「新加坡工業智慧指數」（Singapore Smart Industry Readiness Index, SIRI）：由新加坡政府提出，用於評估企業在工業4.0的發展程度。</span><br><span class="line"></span><br><span class="line">3. 「工業 4.0實施步驟方法論」：這是一種實施工業4.0的具體步驟，包括盤點公司內部待改善問題，分析現況與預期目標差異，以及規劃具體要改善的業務流程路線圖。</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://akasha.github.io/project/2024/04/10/%E8%A8%AD%E5%AE%9A%20API%20Key/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/project/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha使用手冊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | akasha使用手冊">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/project/2024/04/10/%E8%A8%AD%E5%AE%9A%20API%20Key/" class="post-title-link" itemprop="url">設定 API Key</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2024-04-10 08:23:36" itemprop="dateCreated datePublished" datetime="2024-04-10T08:23:36+08:00">2024-04-10</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="openAI-API-Key"><a href="#openAI-API-Key" class="headerlink" title="openAI API Key"></a>openAI API Key</h1></br>
</br>

<h2 id="openAI"><a href="#openAI" class="headerlink" title="openAI:"></a>openAI:</h2><p>如果需要使用openAI的模型，必須先去<a target="_blank" rel="noopener" href="https://platform.openai.com/account/api-keys">openai</a>取得API KEY。取得KEY後，你可以選擇其中一種方法來匯入key:</p>
<h5 id="1-將KEY放於-env檔案中OPENAI-API-KEY-your-api-key"><a href="#1-將KEY放於-env檔案中OPENAI-API-KEY-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中OPENAI_API_KEY&#x3D;your api key"></a>1.將KEY放於.env檔案中OPENAI_API_KEY&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OPENAI_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-OPENAI-API-KEY"><a href="#2-設定成環境變數-變數名-OPENAI-API-KEY" class="headerlink" title="2.設定成環境變數(變數名:OPENAI_API_KEY)"></a>2.設定成環境變數(變數名:OPENAI_API_KEY)</h5><h5 id="3-在terminal中使用export設定環境變數"><a href="#3-在terminal中使用export設定環境變數" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export OPENAI_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-在Python中使用os-environ-‘OPENAI-API-KEY’-your-api-key"><a href="#4-在Python中使用os-environ-‘OPENAI-API-KEY’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘OPENAI_API_KEY’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘OPENAI_API_KEY’]&#x3D;your api key</h5></br>
</br>

<h2 id="Azure-openAI"><a href="#Azure-openAI" class="headerlink" title="Azure openAI"></a>Azure openAI</h2><p>如果你想使用Azure openAI，先去<a target="_blank" rel="noopener" href="https://oai.azure.com/portal">azureAI</a>取得base url 和 API key。</p>
<p>將<em><strong>OPENAI_API_KEY&#x3D;your azure key</strong></em>, <em><strong>OPENAI_API_BASE&#x3D;your Language API base url</strong></em>, <em><strong>OPENAI_API_TYPE&#x3D;azure</strong></em>, <em><strong>OPENAI_API_VERSION&#x3D;2023-05-15</strong></em> 寫於.env檔案並放於你要執行akasha的路徑中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## .env file</span><br><span class="line">AZURE_API_KEY=&#123;your azure key&#125;</span><br><span class="line">AZURE_API_BASE=&#123;your Language API base url&#125;</span><br><span class="line">AZURE_API_TYPE=azure</span><br><span class="line">AZURE_API_VERSION=2023-05-15</span><br></pre></td></tr></table></figure>

<p>:::info<br>請記得在<a target="_blank" rel="noopener" href="https://oai.azure.com/portal">Azure openAI Studio</a>部署所有你需要的模型，且部署名稱與模型名稱相同。<br>:::</p>
</br>
</br>


<h2 id="LLAMA-2"><a href="#LLAMA-2" class="headerlink" title="LLAMA-2"></a>LLAMA-2</h2><p>如果你想使用原版的meta-llama model，並須先去<a target="_blank" rel="noopener" href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/">meta-llama</a>去取得授權，並註冊<a target="_blank" rel="noopener" href="https://huggingface.co/login?next=/settings/tokens">huggingface</a>取得access token，取得授權後才能經由huggingface下載並使用模型。<br><img src="https://hackmd.io/_uploads/H1LOb2ot6.png" alt="granted"></p>
<p>:::info<br>the account on Hugging Face and the email you use to request access to Meta-Llama must be the same, so that you can download models from Hugging Face once your account is approved.</p>
<p>You should see the Gated model You have been granted access to this model once your account is approved<br>:::</p>
</br>
</br>


<p>同樣的，取得huggingface key值後，你可以選擇其中一種方法來匯入key:</p>
<h5 id="1-將KEY放於-env檔案中HF-TOKEN-your-api-key"><a href="#1-將KEY放於-env檔案中HF-TOKEN-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中HF_TOKEN&#x3D;your api key"></a>1.將KEY放於.env檔案中HF_TOKEN&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HF_TOKEN=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-HF-TOKEN"><a href="#2-設定成環境變數-變數名-HF-TOKEN" class="headerlink" title="2.設定成環境變數(變數名:HF_TOKEN)"></a>2.設定成環境變數(變數名:HF_TOKEN)</h5><h5 id="3-在terminal中使用export設定環境變數-1"><a href="#3-在terminal中使用export設定環境變數-1" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HF_TOKEN=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-在Python中使用os-environ-‘HF-TOKEN’-your-api-key"><a href="#4-在Python中使用os-environ-‘HF-TOKEN’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘HF_TOKEN’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘HF_TOKEN’]&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#PYTHON3.8</span><br><span class="line"># os.environ[&#x27;HF_TOKEN&#x27;]=your api key</span><br><span class="line">import akasha</span><br><span class="line">ak = akasha.Doc_QA()</span><br><span class="line">response = ak.get_response(dir_path, prompt, model=&quot;hf:meta-llama/Llama-2-7b-chat-hf&quot;)</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://akasha.github.io/project/2024/03/27/summary/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/project/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha使用手冊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | akasha使用手冊">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/project/2024/03/27/summary/" class="post-title-link" itemprop="url">summary</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2024-03-27 02:37:54" itemprop="dateCreated datePublished" datetime="2024-03-27T02:37:54+08:00">2024-03-27</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="文件摘要"><a href="#文件摘要" class="headerlink" title="文件摘要"></a>文件摘要</h2><p>若要創建文本文件的摘要（.pdf、.txt.、docx），您可以使用 <em><strong>summary.summarize_file</strong></em> 函數。如範例，以下使用 map_reduce 摘要方法指示語言模型生成大約 500 字的摘要。有兩種摘要類型，<em><strong>map_reduce</strong></em> 和 <em><strong>refine</strong></em>，<em><strong>map_reduce</strong></em> 將對每個文本段落進行摘要，然後使用所有摘要的文本段落生成最終摘要；<em><strong>refine</strong></em> 將逐個摘要每個文本段落，並使用前一個摘要作為摘要下一段的提示，以獲得更高水平的摘要一致性。</p>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line">sum = akasha.Summary( chunk_size=1000, chunk_overlap=100)</span><br><span class="line">sum.summarize_file(file_path=&quot;doc/mic/5軸工具機因應市場訴求改變的發展態勢.pdf&quot;,summary_type=&quot;map_reduce&quot;, summary_len=500\</span><br><span class="line">, chunk_overlap=40)</span><br></pre></td></tr></table></figure>

<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### Arguments of Summary class ###</span><br><span class="line"> Args:</span><br><span class="line">            **chunk_size (int, optional)**: chunk size of texts from documents. Defaults to 1000.</span><br><span class="line">            **chunk_overlap (int, optional)**: chunk overlap of texts from documents. Defaults to 40.</span><br><span class="line">            **model (str, optional)**: llm model to use. Defaults to &quot;gpt-3.5-turbo&quot;.</span><br><span class="line">            **verbose (bool, optional)**: show log texts or not. Defaults to False.</span><br><span class="line">            **threshold (float, optional)**: the similarity threshold of searching. Defaults to 0.2.</span><br><span class="line">            **language (str, optional)**: the language of documents and prompt, use to make sure docs won&#x27;t exceed</span><br><span class="line">                max token size of llm input.</span><br><span class="line">            **record_exp (str, optional)**: use aiido to save running params and metrics to the remote mlflow or not if record_exp not empty, and setrecord_exp as experiment name.  default &quot;&quot;.</span><br><span class="line">            **system_prompt (str, optional)**: the system prompt that you assign special instruction to llm model, so will not be used</span><br><span class="line">                in searching relevant documents. Defaults to &quot;&quot;.</span><br><span class="line">            **max_doc_len(int, optional)**: max docuemnt length of llm input. Defaults to 1500.</span><br><span class="line">            **temperature (float, optional)**: temperature of llm model from 0.0 to 1.0 . Defaults to 0.0.</span><br><span class="line">            **auto_translate (bool, optional)**: translate summary into language or not.</span><br><span class="line"></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://akasha.github.io/project/2024/03/20/auto_evaluation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/project/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha使用手冊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | akasha使用手冊">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/project/2024/03/20/auto_evaluation/" class="post-title-link" itemprop="url">auto_evaluation</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2024-03-20 08:44:08" itemprop="dateCreated datePublished" datetime="2024-03-20T08:44:08+08:00">2024-03-20</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Auto-Evaluation"><a href="#Auto-Evaluation" class="headerlink" title="Auto Evaluation"></a>Auto Evaluation</h2><p>若要測試各種參數對語言模型回答的好壞，可以使用auto_evalution函數。首先，您需要基於您要使用的文檔構建一個問題集(.txt)。<br>您可以生成單選題文件或問答題文件。</p>
<ol>
<li>對於<em><strong>單選題文件</strong></em>，每個選項和正確答案之間用制表符(\t)分隔，每行是一個問題，如範例: <figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">應回收廢塑膠容器材質種類不包含哪種?	1.聚丙烯（PP）	2.聚苯乙烯（PS）	3.聚氯乙烯（PVC）	4.低密度聚乙烯（LDPE）	4</span><br><span class="line">庫存盤點包括庫存全盤作業及不定期抽盤作業，盤點計畫應包括下列項目不包含哪項?	1.盤點差異之處理	2.盤點清冊	3.各項物品存放區域配置圖	4.庫存全盤日期及參加盤點人員名單	1</span><br><span class="line">以下何者不是環保署指定之公民營地磅機構?	1.中森加油站企業有限公司	2.台益地磅站	3.大眾地磅站	4.新福行	4</span><br></pre></td></tr></table></figure>
 函數將返回問題集的正確率和使用的token量，每個問題的詳細內容儲存在logs中。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import akasha.eval as eval</span><br><span class="line">import os</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">load_dotenv() </span><br><span class="line"></span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your openAI key&quot;</span><br><span class="line">dir_path = &quot;doc/pvc/&quot;</span><br><span class="line">exp_name = &quot;exp_akasha_auto_evaluation&quot;</span><br><span class="line"></span><br><span class="line">eva = eval.Model_Eval(question_style=&quot;single_choice&quot;, search_type=&#x27;merge&#x27;,\</span><br><span class="line">    model=&quot;openai:gpt-3.5-turbo&quot;, embeddings=&quot;openai:text-embedding-ada-002&quot;,record_exp=exp_name)</span><br><span class="line">print(eva.auto_evaluation(&quot;question_pvc.txt&quot;, dir_path ))</span><br><span class="line">## correct rate: 0.9, tokens: 3228 ##</span><br></pre></td></tr></table></figure></li>
<li>對於<em><strong>問答題文件</strong></em>，每個問題之前有 “問題：”，每個參考答案之前有 “答案：”。每個問題之間用兩個換行符 (\n\n) 分隔。 <figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">問題：根據文件中的訊息，智慧製造的複雜性已超越系統整合商的負荷程度，未來產業鏈中的角色將傾向朝共和共榮共創智慧製造商機，而非過往的單打獨鬥模式發展。請問為什麼  供  應商、電信商、軟體開發商、平台商、雲端服務供應商、系統整合商等角色會傾向朝共和共榮共創智慧製造商機的方向發展？</span><br><span class="line">答案：因為智慧製造的複雜性已超越系統整合商的負荷程度，單一角色難以完成整個智慧製造的需求，而共和共榮共創的模式可以整合各方的優勢，共同創造智慧製造的商機。</span><br><span class="line"></span><br><span class="line">問題：根據文件中提到的資訊技術商（IT）和營運技術商（OT），請列舉至少兩個邊緣運算產品或解決方案。</span><br><span class="line">答案：根據文件中的資訊，NVIDIA的邊緣運算產品包括Jetson系列和EGX系列，而IBM的邊緣運算產品包括IBM Edge Application Manager和IBM Watson Anywhere。</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://akasha.github.io/project/2024/03/12/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/project/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha使用手冊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | akasha使用手冊">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/project/2024/03/12/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/" class="post-title-link" itemprop="url">文件搜尋</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2024-03-12 03:41:16" itemprop="dateCreated datePublished" datetime="2024-03-12T03:41:16+08:00">2024-03-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="選擇不同的文件搜尋方法"><a href="#選擇不同的文件搜尋方法" class="headerlink" title="選擇不同的文件搜尋方法"></a>選擇不同的文件搜尋方法</h2><p>使用<em><strong>search_type</strong></em>參數可選擇不同的文件搜尋方法去找出與問題相關的文件段落，可使用<em><strong>svm</strong></em>, <em><strong>mmr</strong></em>, <em><strong>tfidf</strong></em>, <em><strong>knn</strong></em>。另可使用<em><strong>merge</strong></em>，為前三者的合併。</p>
<ol>
<li><p><em><strong>支持向量機（svm）</strong></em> 使用輸入提示和文件向量來訓練svm模型，訓練後，svm可用於基於其與訓練數據的相似性對新向量進行評分。</p>
</li>
<li><p><em><strong>Max Marginal Relevance（mmr）</strong></em> 通過余弦相似度選擇相似的文件，但它也考慮多樣性，因此它還會懲罰與已選擇文件的接近。</p>
</li>
<li><p><em><strong>詞頻-逆文檔頻率（tfidf）</strong></em> 是信息檢索和文本挖掘中常用的權重技術。TF-IDF是一種統計方法，用於評估詞語在一個文檔集合或語料庫中相對於該集合中的一個特定文檔的重要性。</p>
</li>
<li><p><em><strong>K-最近鄰居（KNN）</strong></em> 是一種機器學習算法，用於分類和回歸問題。對於新數據點，它計算其與已知數據點的距離，然後基於最近的 k 個鄰居來預測類別或數值。在分類中，以多數票決定類別，而在回歸中則計算鄰居的平均值。</p>
</li>
<li><p>***Okapi BM25(bm25)***（BM 是最佳匹配的縮寫）是一種基於查詢詞出現在每個文檔中的檢索功能，而不考慮它們在文檔中的相鄰關系的排名一組文檔的方法。它是一系列具有略有不同組件和參數的評分函數。</p>
</br>
</br></li>
</ol>
<h2 id="自動選擇搜尋方法"><a href="#自動選擇搜尋方法" class="headerlink" title="自動選擇搜尋方法"></a>自動選擇搜尋方法</h2><p><em><strong>auto</strong></em>是另一種可以選擇的文件搜尋策略，使用<em><strong>bm25</strong></em>&#x2F;<em><strong>tfidf</strong></em>來搜尋相同詞語的文件，並用svm搜尋近似詞意的文件，若兩者皆沒有找到，則使用rerank模型去遍歷文件，但會相當緩慢。</p>
<h2 id="自訂搜尋方法"><a href="#自訂搜尋方法" class="headerlink" title="自訂搜尋方法"></a>自訂搜尋方法</h2><p>如果你希望設計自己的方法找尋最相似的文檔，可以建立search_type函數，並將此函數作為<em><strong>search_type</strong></em>參數</p>
<p>此函數輸入包含:</p>
<h5 id="1-query-embeds-查詢的嵌入。（numpy-array）"><a href="#1-query-embeds-查詢的嵌入。（numpy-array）" class="headerlink" title="1.query_embeds: 查詢的嵌入。（numpy array）"></a>1.query_embeds: 查詢的嵌入。（numpy array）</h5><h5 id="2-docs-embeds-所有文檔的嵌入。（表示文檔嵌入的-numpy-數組的list）"><a href="#2-docs-embeds-所有文檔的嵌入。（表示文檔嵌入的-numpy-數組的list）" class="headerlink" title="2.docs_embeds: 所有文檔的嵌入。（表示文檔嵌入的 numpy 數組的list）"></a>2.docs_embeds: 所有文檔的嵌入。（表示文檔嵌入的 numpy 數組的list）</h5><h5 id="3-k-所要選擇的最相關文檔的數量。（integer）"><a href="#3-k-所要選擇的最相關文檔的數量。（integer）" class="headerlink" title="3.k: 所要選擇的最相關文檔的數量。（integer）"></a>3.k: 所要選擇的最相關文檔的數量。（integer）</h5><h5 id="4-relevancy-threshold-相關性閾值。如果查詢和文檔之間的距離小於-relevancy-threshold，則選擇該文檔。（float）"><a href="#4-relevancy-threshold-相關性閾值。如果查詢和文檔之間的距離小於-relevancy-threshold，則選擇該文檔。（float）" class="headerlink" title="4.relevancy_threshold: 相關性閾值。如果查詢和文檔之間的距離小於 relevancy_threshold，則選擇該文檔。（float）"></a>4.relevancy_threshold: 相關性閾值。如果查詢和文檔之間的距離小於 relevancy_threshold，則選擇該文檔。（float）</h5><h5 id="5-log-一個字典，可用於記錄任何您希望記錄的其他信息。（dictionary）"><a href="#5-log-一個字典，可用於記錄任何您希望記錄的其他信息。（dictionary）" class="headerlink" title="5.log: 一個字典，可用於記錄任何您希望記錄的其他信息。（dictionary）"></a>5.log: 一個字典，可用於記錄任何您希望記錄的其他信息。（dictionary）</h5></br>
</br>

<h4 id="此函數須回傳相似文檔的index順序-list"><a href="#此函數須回傳相似文檔的index順序-list" class="headerlink" title="此函數須回傳相似文檔的index順序(list)"></a>此函數須回傳相似文檔的index順序(list)</h4></br>
</br>


<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><p>如範例，我們使用歐幾里得距離度量來識別最相關的文檔。它返回一個表示距離小於指定閾值的查詢和文檔嵌入之間的前 k 個文檔的索引列表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">def cust(query_embeds, docs_embeds, k:int, relevancy_threshold:float, log:dict):</span><br><span class="line">    </span><br><span class="line">    from scipy.spatial.distance import euclidean</span><br><span class="line">    import numpy as np</span><br><span class="line">    distance = [[euclidean(query_embeds, docs_embeds[idx]),idx] for idx in range(len(docs_embeds))]</span><br><span class="line">    distance = sorted(distance, key=lambda x: x[0])</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    ## change dist if embeddings not between 0~1</span><br><span class="line">    max_dist = 1</span><br><span class="line">    while max_dist &lt; distance[-1][0]:</span><br><span class="line">        max_dist *= 10</span><br><span class="line">        relevancy_threshold *= 10</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    ## add log para</span><br><span class="line">    log[&#x27;dd&#x27;] = &quot;miao&quot;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    return  [idx for dist,idx in distance[:k] if (max_dist - dist) &gt;= relevancy_threshold]</span><br><span class="line"></span><br><span class="line">doc_path = &quot;./mic/&quot;</span><br><span class="line">prompt = &quot;五軸是什麼?&quot;</span><br><span class="line"></span><br><span class="line">qa = akasha.Doc_QA(verbose=True, search_type = cust, embeddings=&quot;hf:shibing624/text2vec-base-chinese&quot;)</span><br><span class="line">qa.get_response(doc_path= doc_path, prompt = prompt)</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一頁" aria-label="上一頁" href="/project/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/project/">1</a><span class="page-number current">2</span><a class="page-number" href="/project/page/3/">3</a><a class="page-number" href="/project/page/4/">4</a><a class="extend next" rel="next" title="下一頁" aria-label="下一頁" href="/project/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Chih Chuan Chang<ccchang@iii.org.tw></span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="回到頂端">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/project/js/comments.js"></script><script src="/project/js/utils.js"></script><script src="/project/js/motion.js"></script><script src="/project/js/sidebar.js"></script><script src="/project/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/project/js/third-party/search/local-search.js"></script>







  





</body>
</html>
